{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run _if_on_colab_setup_flamedisx.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yqnc41Mh8cdy",
    "outputId": "b70874ce-5be0-4bd3-b16d-48af0e6c8841"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.0', False, False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "np = pd.np\n",
    "import flamedisx as fd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "have_gpu = tf.test.is_gpu_available()\n",
    "tf.__version__, tf.test.is_built_with_gpu_support(), have_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R7m4T5PLvc5E",
    "outputId": "3d634db3-cc42-4b7f-c671-fa1f8f41f315"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'flamedisx' from '/home/aalbers/software/flamedisx/flamedisx/__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart runtime if this says: <module 'flamedisx' (namespace)>\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flamedisx as fd\n",
    "fd.LXeSource.tpc_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSwMIA4TMDl9"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Sensitivity:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 fv=1.3,  # FV to use (approx, just shrinking radius of Xe1T)\n",
    "                 exposure_mult=1.0,   # Multiplier for true exposure\n",
    "                 mwimp=2e2,  # WIMP mass\n",
    "                 xsec=4.7e-47,  # cm^2 xsec to use\n",
    "                 n_spectra=1,  # Number of time points to compute WIMP spectra for\n",
    "                 e_rec_max=50.,  # Max recoil energy in WIMP spectra [keV]\n",
    "                 batch_size=700 if have_gpu else 20,  # Number of events per batch in each source\n",
    "                 ):\n",
    "        assert n_spectra > 0\n",
    "        \n",
    "        # Calculate radius of detector volume\n",
    "        # TODO: also adjust z\n",
    "        r = fd.LXeSource.tpc_radius\n",
    "        l = fd.LXeSource.tpc_length\n",
    "        v_xe1t = np.pi * r ** 2 * l\n",
    "        v_small = v_xe1t / 2 * fv\n",
    "        r_small = (v_small / l / np.pi)**0.5\n",
    "        print(f'TPC with radius {r_small :.3g} cm holds {fv} tonnes LXe')\n",
    "    \n",
    "        class myERSource(fd.SR1ERSource):\n",
    "            tpc_radius = r_small  # cm\n",
    "            \n",
    "\n",
    "        class myWIMPSource(fd.SR1WIMPSource):\n",
    "            tpc_radius = r_small  # cm\n",
    "    \n",
    "            # WIMP settings\n",
    "            mw = mwimp\n",
    "            n_in = n_spectra + 1  # n_in is bin_edges\n",
    "            es = np.geomspace(0.7, e_rec_max, 100)\n",
    "            sigma_nucleon = xsec\n",
    "        \n",
    "        self.lf = fd.LogLikelihood(sources=dict(er=myERSource,\n",
    "                                                wimp=myWIMPSource),\n",
    "                                   free_rates=('er', 'wimp'),\n",
    "                                   batch_size=batch_size)\n",
    "        \n",
    "        # Set true rate multipliers such that mean number of\n",
    "        # ER events is about 627 and WIMP events is about 3.56\n",
    "        # TODO: can probably call mu_itps here\n",
    "        self.er_rate_true = 627 / self.lf.sources['er'].estimate_mu()\n",
    "        self.wimp_rate_true = 3.56 / self.lf.sources['wimp'].estimate_mu()\n",
    "        print(f\"True rate multipliers: ER {self.er_rate_true :.3g},\"\n",
    "              f\" NR {self.wimp_rate_true :.3g}\")\n",
    "\n",
    "        # UL only\n",
    "        self.crit_val = scipy.stats.norm.ppf(0.9) ** 2\n",
    "\n",
    "    def ll_check(self, bf, ll_best=None):\n",
    "        \"\"\"Return dictionary with points for likelihood parabola plot\"\"\"\n",
    "        # TODO: shouldn't we refit er_rate_multiplier each time here?\n",
    "        # Well, depends on what you want to draw...\n",
    "        if ll_best is None:\n",
    "            ll_best = self.lf(**bf)\n",
    "    \n",
    "        xs = np.linspace(0.0, 3.5, 50)\n",
    "        ys = np.array([self.lf(wimp_rate_multiplier=x,\n",
    "                               er_rate_multiplier=bf['er_rate_multiplier'])\n",
    "                       for x in xs])\n",
    "        return dict(xs=xs, ys=ys, ll_best=ll_best)\n",
    "\n",
    "    def toymc(self, do_ll_check=False):\n",
    "        # Simulate background-only data\n",
    "        d = self.lf.simulate(er_rate_multiplier=self.er_rate_true,\n",
    "                             wimp_rate_multiplier=0.)\n",
    "        self.lf.set_data(d)\n",
    "    \n",
    "        guess = dict(er_rate_multiplier=0.9,\n",
    "                     wimp_rate_multiplier=0.1)\n",
    "    \n",
    "        # Determine the global best fit\n",
    "        bf = self.lf.bestfit(guess=guess, llr_tolerance=0.0002)\n",
    "        ll_best = self.lf(**bf)\n",
    "    \n",
    "        ul_guess = bf.copy()\n",
    "        wrm_guess = max(1.5, 3 * bf['wimp_rate_multiplier'])\n",
    "        ul_guess['wimp_rate_multiplier'] = wrm_guess\n",
    "    \n",
    "        def t_stat(wimp_rate_multiplier):\n",
    "            return -2 * (self.lf(er_rate_multiplier=bf['er_rate_multiplier'],\n",
    "                                 wimp_rate_multiplier=wimp_rate_multiplier)\n",
    "                         - ll_best)\n",
    "    \n",
    "        while t_stat(wrm_guess) < self.crit_val:\n",
    "            wrm_guess += 0.5\n",
    "            print(f'increasing ul_guess to {wrm_guess}')\n",
    "        ul_guess['wimp_rate_multiplier'] = wrm_guess\n",
    "    \n",
    "        ul = self.lf.one_parameter_interval('wimp_rate_multiplier',\n",
    "                                            bestfit=bf,\n",
    "                                            guess=ul_guess,\n",
    "                                            llr_tolerance=0.0002)\n",
    "        check = dict()\n",
    "        if do_ll_check:\n",
    "            check = self.ll_check(bf, ll_best=ll_best)\n",
    "        \n",
    "        return {**bf, **check,\n",
    "                'ul':ul,\n",
    "                'ul_guess': ul_guess['wimp_rate_multiplier']}\n",
    "        \n",
    "    def run_toys(self, n, do_ll_check=False, df=True, save_name=None):\n",
    "        res = np.array([self.toymc(do_ll_check=do_ll_check)\n",
    "                        for _ in tqdm(range(n))])\n",
    "        \n",
    "        if df or save_name is not None:\n",
    "            d = defaultdict(list)\n",
    "            for toy in res:\n",
    "                for k, v in toy.items():\n",
    "                    d[k].append(v)\n",
    "            res_df = pd.DataFrame(d)\n",
    "        \n",
    "        if save_name is not None:\n",
    "            res_df.to_pickle(save_name)\n",
    "        \n",
    "        if df:\n",
    "            return res_df\n",
    "        return res\n",
    "    \n",
    "    def sim_set_and_call(self):\n",
    "        d = self.lf.simulate(er_rate_multiplier=self.er_rate_true,\n",
    "                             wimp_rate_multiplier=0.)\n",
    "        self.lf.set_data(d)\n",
    "\n",
    "        lnL = self.lf()\n",
    "        return d, lnL\n",
    "    \n",
    "    def load(self, names):\n",
    "        dfs = []\n",
    "        for name in names:\n",
    "            dfs.append(pd.read_pickle(name))\n",
    "        return pd.concat(dfs, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vNxZsdRyUw2"
   },
   "source": [
    "# Run toyMCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "lpFflZ7q_CNT",
    "outputId": "5ed72581-855f-41f9-eb56-79b5b823e8e6"
   },
   "outputs": [],
   "source": [
    "sensitivity = Sensitivity(\n",
    "    fv=1.3,  # FV to use (approx, just shrinking radius of Xe1T)\n",
    "    mwimp=2e1,  # WIMP mass\n",
    "    xsec=4.7e-47,  # cm^2 xsec to use\n",
    "    n_spectra=1,  # Number of WIMP spectra to use\n",
    "    e_rec_max=50.,  # Max recoil energy in WIMP spectra [keV]\n",
    "    batch_size=700,  # Number of events per batch in each source\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "ijvHfmkm8MF5",
    "outputId": "c49c85c3-fd4d-4a5e-dd12-8713039b22d1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Set some data and call likelihood, this will trigger the tracing (takes about 7 seconds)\n",
    "a, b = sensitivity.sim_set_and_call()\n",
    "print(len(a), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "4YCjVuH7Cx0Y",
    "outputId": "38b43e98-705a-4e65-9d4a-1c8134462bc2"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now calling likelihood should be fast (~250 ms)\n",
    "sensitivity.lf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lteNPqFhQAIo",
    "outputId": "670e4d4a-6718-4c2e-f95d-7ed13dccfd9a"
   },
   "outputs": [],
   "source": [
    "toys_df_mod = sensitivity.run_toys(200, do_ll_check=False, save_name='toys_mw20.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tg3UtjyTgJeN"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "jm3IwMvlHWbe",
    "outputId": "fb037f6c-78b4-48c0-d563-9841725acbff"
   },
   "outputs": [],
   "source": [
    "toys_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "aCuZqOEYhey4",
    "outputId": "9127fb1c-eb12-4938-dff3-dc175b34d865"
   },
   "outputs": [],
   "source": [
    "plt.scatter(toys_df['wimp_rate_multiplier'],\n",
    "            toys_df['er_rate_multiplier'],\n",
    "            s=3)\n",
    "plt.axhline(sensitivity.er_rate_true, color='r', linestyle='--')\n",
    "plt.axvline(0., color='r', linestyle='--')\n",
    "plt.xlabel('wimp_rate_multiplier')\n",
    "plt.ylabel('er_rate_multiplier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "OLILrVbDzBqq",
    "outputId": "6d2e0dfa-3000-40ff-ecbf-52b007f93045"
   },
   "outputs": [],
   "source": [
    "plt.scatter(toys_df['ul'],\n",
    "            toys_df['er_rate_multiplier'],\n",
    "            s=3)\n",
    "plt.axhline(sensitivity.er_rate_true, color='r', linestyle='--')\n",
    "plt.axvline(0., color='r', linestyle='--')\n",
    "plt.xlabel('ul')\n",
    "plt.ylabel('er_rate_multiplier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4h1mFcB0Dux"
   },
   "outputs": [],
   "source": [
    "chi2 = scipy.stats.chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mrCMaLfb0Jne"
   },
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 3.5, 100)\n",
    "ys = 0.5 * chi2.pdf(xs, df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "r9G2C2oCySBv",
    "outputId": "de19a6b1-8e77-405a-a327-226a9a2fa15e"
   },
   "outputs": [],
   "source": [
    "plt.hist(toys_df['wimp_rate_multiplier'], bins=50, density=1, histtype='step')\n",
    "plt.plot(xs, ys)\n",
    "#plt.ylim(0, 2)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "D9lQJVtkWKUe",
    "outputId": "773ba54f-21af-4eb4-d4b8-b7ed637b7db1"
   },
   "outputs": [],
   "source": [
    "xsec = toys_df['ul'] * 4.7e-47\n",
    "plt.hist(xsec, bins=100, histtype='step')\n",
    "plt.axvline(np.median(xsec), color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LuHEJBEFLyUV",
    "outputId": "2091a0e8-4693-4d16-a070-9e013b38499e"
   },
   "outputs": [],
   "source": [
    "np.min(toys_df['ul']), np.median(toys_df['ul']), np.max(toys_df['ul'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmdfbECWcXCy"
   },
   "source": [
    "# Check lnL parabola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OnnuUodcu3Wi"
   },
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (9, 6),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YafNNWe6sDh5"
   },
   "outputs": [],
   "source": [
    "def ll_plot(data, title=\"\", save_name=None):\n",
    "    xs = data['xs']\n",
    "    ys = data['ys']\n",
    "    ll_best = data['ll_best']\n",
    "    ul = data['ul']\n",
    "    wimp_rm = data['wimp_rate_multiplier']\n",
    "    er_rm = data['er_rate_multiplier']\n",
    "    ul_guess = data['ul_guess']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(xs, -2*(ys-ll_best), label=r'$2\\ln\\mathcal{L}_{best} -2\\ln\\mathcal{L}(\\theta)$')\n",
    "    plt.plot(xs, (-2*(ys-ll_best)-crit_val)**2, label=r'$(2\\ln\\mathcal{L}_{best} -2\\ln\\mathcal{L}(\\theta) - v_{crit})^2$')\n",
    "\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.axhline(crit_val, color='red', label=r'$v_{crit}$')\n",
    "\n",
    "    plt.axvline(wimp_rm, color='k', linestyle='--', label=r'$\\theta_{best}$')\n",
    "    plt.axvline(ul, color='g', linestyle='--', label=r'$\\theta_{UL}$')\n",
    "    plt.axvline(ul_guess, color='magenta', linestyle='--', label=r'$\\theta_{start}$')\n",
    "\n",
    "    plt.ylim(-1, 8)\n",
    "    plt.xlim(0.0, 3.5)\n",
    "    plt.xlabel('wimp_rate_multiplier')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(title)\n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name + '.png', dpi=200, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UR9mCmfIZDTD",
    "outputId": "d0d0e746-6b30-4c58-a3ac-acee7fc06f9a"
   },
   "outputs": [],
   "source": [
    "for idx, toy in toys_df.iterrows():\n",
    "    ll_plot(toy, title=f'Toy #{idx}') # , save_name=f'toy_{idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YU6M-8mJMiHa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "flamedisx_sensitivity.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
